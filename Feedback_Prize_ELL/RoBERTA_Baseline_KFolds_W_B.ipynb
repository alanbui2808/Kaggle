{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPcGH9GnzkDjKM4keH/o8md"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8b71fc0451f54b33accbfb4ca2939090":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_327e1afa54f14446acfd35e303ab933d","IPY_MODEL_c25808cb7adf4a73b08f7eda4dfc8148","IPY_MODEL_116a2ad6d4774924bc3938031d8b0e0b"],"layout":"IPY_MODEL_8493ee3a112b4ef7af7314191aa58d63"}},"327e1afa54f14446acfd35e303ab933d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb21141aa4164125803657e093bec474","placeholder":"​","style":"IPY_MODEL_354f01cc34ea48d6a653efc0e4d3b819","value":"Downloading (…)lve/main/config.json: 100%"}},"c25808cb7adf4a73b08f7eda4dfc8148":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03db642f134941e1bc6e845765e62163","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37573542cbd34d89a8203bb1e7bc9174","value":481}},"116a2ad6d4774924bc3938031d8b0e0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_215e2983ad8049c7b0d70ea20656adcf","placeholder":"​","style":"IPY_MODEL_23de7431d954450ba9dd437b1808f5d0","value":" 481/481 [00:00&lt;00:00, 13.6kB/s]"}},"8493ee3a112b4ef7af7314191aa58d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb21141aa4164125803657e093bec474":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"354f01cc34ea48d6a653efc0e4d3b819":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03db642f134941e1bc6e845765e62163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37573542cbd34d89a8203bb1e7bc9174":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"215e2983ad8049c7b0d70ea20656adcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23de7431d954450ba9dd437b1808f5d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38c3b861bf8242f2ab23e82bc3da7c53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08c90026acdc4417a2d32e1fff681508","IPY_MODEL_508b0cf60182412abc20af0aea28ff6e","IPY_MODEL_577e1e89395e4db5879e84f1302d04ba"],"layout":"IPY_MODEL_6a2f6113453948d58e0311497cd53708"}},"08c90026acdc4417a2d32e1fff681508":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9012c1c7c16b488ca706147c6f0d60d5","placeholder":"​","style":"IPY_MODEL_2f9c35fa3d294bfcb989cd095e1594d5","value":"Downloading (…)olve/main/vocab.json: 100%"}},"508b0cf60182412abc20af0aea28ff6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbbfe2ca7d994dfe8b372ad140e94196","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c0a1b35821c4567859fcf1957a28bb8","value":898823}},"577e1e89395e4db5879e84f1302d04ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_722a4bc8cdaf439893c23bc06855fc1b","placeholder":"​","style":"IPY_MODEL_b0a33d02d9884208859ddc65215632c3","value":" 899k/899k [00:00&lt;00:00, 6.44MB/s]"}},"6a2f6113453948d58e0311497cd53708":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9012c1c7c16b488ca706147c6f0d60d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f9c35fa3d294bfcb989cd095e1594d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbbfe2ca7d994dfe8b372ad140e94196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c0a1b35821c4567859fcf1957a28bb8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"722a4bc8cdaf439893c23bc06855fc1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0a33d02d9884208859ddc65215632c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecbeff02a96b46f1931b65cec858ec6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_873ac7e9da1e4930b2da0344b5bfdefb","IPY_MODEL_6eb75109a08943cab874708d4ec7453f","IPY_MODEL_dcce7e8b24c14b02a584c19430f54457"],"layout":"IPY_MODEL_03675d2099da4941b8fc8586acf49e11"}},"873ac7e9da1e4930b2da0344b5bfdefb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfce8c45dbd84bb198e8d0ec1b5c3196","placeholder":"​","style":"IPY_MODEL_12638b9d2b8c42f8891b06f00dcc5a22","value":"Downloading (…)olve/main/merges.txt: 100%"}},"6eb75109a08943cab874708d4ec7453f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3a04eb2827d4b0ebaa704f8054c02ab","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b12fb73c2f704ff99f95b92e263c209c","value":456318}},"dcce7e8b24c14b02a584c19430f54457":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5db24d0ba37e4094af1f887d123b345d","placeholder":"​","style":"IPY_MODEL_ef91ffe0c4b34c97913cd7fc2124c5c2","value":" 456k/456k [00:00&lt;00:00, 5.72MB/s]"}},"03675d2099da4941b8fc8586acf49e11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfce8c45dbd84bb198e8d0ec1b5c3196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12638b9d2b8c42f8891b06f00dcc5a22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3a04eb2827d4b0ebaa704f8054c02ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b12fb73c2f704ff99f95b92e263c209c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5db24d0ba37e4094af1f887d123b345d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef91ffe0c4b34c97913cd7fc2124c5c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d17a83730e5f415fb90f7ed6f4addc33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7be77610293d4baa87add4ea99f12fa5","IPY_MODEL_91da625bf8d24747b6e841deafa64565","IPY_MODEL_da4ee732c38340bdac79f776d6f02b1e"],"layout":"IPY_MODEL_63b0ec126f534148b72e30102606c04b"}},"7be77610293d4baa87add4ea99f12fa5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd39009881e8425ca215bf7247157198","placeholder":"​","style":"IPY_MODEL_967f1bf1d193496c832b2069319a035d","value":"Downloading (…)/main/tokenizer.json: 100%"}},"91da625bf8d24747b6e841deafa64565":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79f93df9b289461bb5b00fca1464286b","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce1d544b84ad41a6baa1d7f746e63565","value":1355863}},"da4ee732c38340bdac79f776d6f02b1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52dfbb15d5414538898ebdd162a3113e","placeholder":"​","style":"IPY_MODEL_e5bcfa75918a4dd0bdb5dab67b2e74ce","value":" 1.36M/1.36M [00:00&lt;00:00, 10.6MB/s]"}},"63b0ec126f534148b72e30102606c04b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd39009881e8425ca215bf7247157198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"967f1bf1d193496c832b2069319a035d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79f93df9b289461bb5b00fca1464286b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce1d544b84ad41a6baa1d7f746e63565":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52dfbb15d5414538898ebdd162a3113e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5bcfa75918a4dd0bdb5dab67b2e74ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfGZhn9cJPCE","executionInfo":{"status":"ok","timestamp":1692759488189,"user_tz":240,"elapsed":1096,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"faabf1eb-37f0-45ea-fc29-3f640d2fc5b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Kaggle/Feedback_Prize_ELL/Silver\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n","FOLDERNAME = 'Kaggle/Feedback_Prize_ELL/Silver'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install -q iterative-stratification==0.1.7\n","!pip install wandb"],"metadata":{"id":"Ew3O9a5aKhqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import gc\n","import sys\n","import random\n","import platform\n","\n","import numpy as np\n","import pandas as pd\n","from rich import progress\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.utils.data import Dataset, DataLoader\n","\n","import transformers\n","from transformers import get_cosine_schedule_with_warmup\n","\n","from sklearn.metrics import mean_squared_error\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","import wandb\n","import warnings\n","warnings.simplefilter('ignore')"],"metadata":{"id":"gIes9Gb0JWbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAIN_PATH = \"../input/train.csv\"\n","TEST_PATH = \"../input/test.csv\""],"metadata":{"id":"HN0Nbp2tJbpw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(TRAIN_PATH)\n","test = pd.read_csv(TEST_PATH)"],"metadata":{"id":"hxGnjeVPJdM-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Custom Functions"],"metadata":{"id":"X639rDbENfmw"}},{"cell_type":"code","source":["def wandb_log(**kwargs):\n","    for k, v in kwargs.item():\n","        wandb.log({k: v})\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=42)"],"metadata":{"id":"Ap6QZYriNc2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MCRMSE - Mean Columnwise Root Mean Square Error\n","Basically mean (RMSE) of all columns where each column is a separate target variable.\n","\n","$$MCRMSE = \\frac{1}{m} \\sum_{j=1}^m \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{ij} - \\hat{y}_{ij})^2}$$\n","\n","where:\n","- $m$ is the number of predicted variables (number of columns)\n","- $n$ is number of test samples (number of rows)\n","- $y_{ij}$ - $i^{th}$ actual value of $j^{th}$ variable.\n","- $\\hat{y}_{ij}$ - $i^{th}$ predicted value of $j^{th}$ variable.\n","\n","The part inside the $\\sqrt{(\\cdot)}$ is the original RMSE of each column."],"metadata":{"id":"xvBeGkbbOvQG"}},{"cell_type":"code","source":["def MCRMSE(y_trues, y_preds):\n","    '''\n","    Both y_trues and y_preds is N*M where\n","    '''\n","\n","    y_trues = np.asarray(y_trues)\n","    y_preds = np.asarray(y_preds)\n","    scores = []\n","    m = y_trues.shape[1]\n","\n","    for j in range(m):\n","        # take entire column j from both y_true and y_pred\n","        y_true = y_trues[:, j]\n","        y_pred = y_preds[:, j]\n","        # calculate rmse\n","        rmse = mean_squared_error(y_true, y_pred, squared=False)\n","        scores.append(rmse)\n","\n","    mcrmse = np.mean(scores)\n","    return mcrmse\n"],"metadata":{"id":"_sFNt5pfOteQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Config = {\n","    'TRAIN_BS': 16,\n","    'VALID_BS': 16,\n","    'MODEL_NAME': 'roberta-large',\n","    'TOKENIZER': transformers.AutoTokenizer.from_pretrained('roberta-base', use_fast=True),\n","    'NUM_WORKERS': 8,\n","    # GradScaler helps harness the computational benefits of mixed-precision training while addressing the challenges of numerical stability.\n","    # It's particularly useful when training deep learning models on GPUs with mixed-precision capabilities to achieve faster training times and better resource utilization.\n","    'scaler': GradScaler(),\n","    'FILE_PATH': '../input/feedback-prize-english-language-learning/train.csv',\n","    # Uses for multi-target regression\n","    # combines the qualities of both MSE and MAE.\n","    # It's smooth around zero but less sensitive to outliers compared to MSE.\n","    # Mathematically, it switches between an L1 loss and an L2 loss based on a threshold.\n","    'LOSS': 'SmoothL1Loss',\n","    'EVAL_METRIC': 'MCRMSE',\n","    'NB_EPOCHS': 5,\n","    'SPLITS': 5,\n","    'T_0': 20,\n","    'η_min': 1e-4,\n","    'fc_dropout': 0.2,\n","    'betas': (0.9, 0.999),\n","    'MAX_LEN': 200,\n","    'N_LABELS': 6,\n","    'LR': 2e-4,\n","    'competition': 'feedback_3',\n","    '_wandb_kernel': 'tanaym',\n","}\n"],"metadata":{"id":"kRR7Hm7xYRza","executionInfo":{"status":"ok","timestamp":1692760618223,"user_tz":240,"elapsed":1749,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["8b71fc0451f54b33accbfb4ca2939090","327e1afa54f14446acfd35e303ab933d","c25808cb7adf4a73b08f7eda4dfc8148","116a2ad6d4774924bc3938031d8b0e0b","8493ee3a112b4ef7af7314191aa58d63","fb21141aa4164125803657e093bec474","354f01cc34ea48d6a653efc0e4d3b819","03db642f134941e1bc6e845765e62163","37573542cbd34d89a8203bb1e7bc9174","215e2983ad8049c7b0d70ea20656adcf","23de7431d954450ba9dd437b1808f5d0","38c3b861bf8242f2ab23e82bc3da7c53","08c90026acdc4417a2d32e1fff681508","508b0cf60182412abc20af0aea28ff6e","577e1e89395e4db5879e84f1302d04ba","6a2f6113453948d58e0311497cd53708","9012c1c7c16b488ca706147c6f0d60d5","2f9c35fa3d294bfcb989cd095e1594d5","fbbfe2ca7d994dfe8b372ad140e94196","2c0a1b35821c4567859fcf1957a28bb8","722a4bc8cdaf439893c23bc06855fc1b","b0a33d02d9884208859ddc65215632c3","ecbeff02a96b46f1931b65cec858ec6e","873ac7e9da1e4930b2da0344b5bfdefb","6eb75109a08943cab874708d4ec7453f","dcce7e8b24c14b02a584c19430f54457","03675d2099da4941b8fc8586acf49e11","bfce8c45dbd84bb198e8d0ec1b5c3196","12638b9d2b8c42f8891b06f00dcc5a22","c3a04eb2827d4b0ebaa704f8054c02ab","b12fb73c2f704ff99f95b92e263c209c","5db24d0ba37e4094af1f887d123b345d","ef91ffe0c4b34c97913cd7fc2124c5c2","d17a83730e5f415fb90f7ed6f4addc33","7be77610293d4baa87add4ea99f12fa5","91da625bf8d24747b6e841deafa64565","da4ee732c38340bdac79f776d6f02b1e","63b0ec126f534148b72e30102606c04b","fd39009881e8425ca215bf7247157198","967f1bf1d193496c832b2069319a035d","79f93df9b289461bb5b00fca1464286b","ce1d544b84ad41a6baa1d7f746e63565","52dfbb15d5414538898ebdd162a3113e","e5bcfa75918a4dd0bdb5dab67b2e74ce"]},"outputId":"ccbfdad2-7d8a-4bec-fbe5-f19419a03669"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b71fc0451f54b33accbfb4ca2939090"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c3b861bf8242f2ab23e82bc3da7c53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecbeff02a96b46f1931b65cec858ec6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d17a83730e5f415fb90f7ed6f4addc33"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Weights and Biases"],"metadata":{"id":"tF6BALMoYWzk"}},{"cell_type":"markdown","source":["WandB is a developer tool for companies turn deep learning research projects into deployed software by helping teams track their models, visualize model performance and easily automate training and improving models. We will use their tools to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.\n","\n"],"metadata":{"id":"mKQtFFwTYf4n"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"cfFGEHCdZ7JD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"7V3KGms3Z8pw"}},{"cell_type":"code","source":["class FeedBackDataset(Dataset):\n","    def __init__(self, data, is_test=False):\n","        self.data = data\n","        self.is_test = is_test\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # .values access the underlying numpy array of DataFrame\n","        text = self.data['full_text'].values\n","        labels = self.data[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].values\n","        inputs = self._tokenize_texts(text[idx])\n","\n","        if not self.is_test:\n","            targets = torch.tensor(labels[idx], dtype=torch.float)\n","            return inputs, targets\n","\n","    def _tokenize_texts(self, text):\n","        # .encode_plus provides more flexibity and customization than .encode\n","        inputs = Config['TOKENIZER'].encode_plus(\n","            text,\n","            return_tensors=None, # here we dont return tensors but simply a dict\n","            add_special_tokens=True,\n","            max_length=Config['MAX_LEN'],\n","            pad_to_max_length=True,\n","            truncation=True\n","        )\n","\n","        for k, v in inputs.items():\n","            # convert to tensor.long, enhance precision (64bits)\n","            inputs[k] = torch.tensor(v, dtype=torch.long)\n","\n","        return inputs\n"],"metadata":{"id":"kHdqWwHvZ7uk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data preprocessing"],"metadata":{"id":"Tj6NcwSTrjIa"}},{"cell_type":"markdown","source":["We could apply typical text preprocessing steps such as removing stopwords and punctuations are generally not necessary or even recommended when training BERT and similar transformer-based models. BERT is designed to learn from the raw text data and handle various linguistic features, including stopwords and punctuation, on its own. Applying traditional preprocessing steps can actually hinder the performance of transformer models like BERT. Here's why:\n","\n","\\\\\n","\n"," 1. **Contextual Learning**: BERT is a contextual language model that learns representations by considering the surrounding words in a sentence. Removing stopwords can disrupt the context and structure of the sentence, which is crucial for BERT's understanding.\n","\n","2. **Positional Information**: Transformer models rely on positional information of words in a sentence. Punctuation marks contribute to this positional information, and removing them might negatively impact the model's ability to understand sentence structure.\n","\n","3. **Fine-tuning**: When fine-tuning BERT for specific downstream tasks (e.g., sentiment analysis, text classification), it's recommended to keep the input text as close to the original as possible. Removing stopwords might remove important information that the model needs to make accurate predictions.\n","\n","4. **Efficiency**: Transformer models like BERT can handle a wide range of linguistic variations and complexities. Removing stopwords might not provide significant benefits in terms of model efficiency or performance improvement.\n","\n","5. **Tokenization**: BERT tokenizes input text into subword tokens, including punctuation and special characters. Removing punctuation before tokenization could lead to tokenization mismatch between your preprocessed data and the model's tokenizer.\n","\n","But we could apply lowercasing and remove links, remove words containing numbers."],"metadata":{"id":"tJODk7R9trwy"}},{"cell_type":"code","source":["import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer"],"metadata":{"id":"4TGqFfextuNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_text(text):\n","    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","    and remove words containing numbers.\n","    - Reason why we remove digits/ numbers from the text is because we reduce noise if we use models that based on word\n","    embeddings such as Word2Vec, BERT etc. These models are designed to capture semantic relationships between words.\n","    - When performing text analysis, it's often useful to treat different forms of a word (e.g., \"run,\" \"running,\" \"ran\") as the same word.\n","    Including digits within words (e.g., \"running123\") could prevent effective word normalization.\n","    '''\n","    text = str(text).lower()\n","    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n","    text = re.sub('\\w*\\d\\w*', '', text)\n","    return text"],"metadata":{"id":"AipsEpItu0Ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Text processing using regular expression is much faster than simple for loop + condition checking.\n","train['full_text'] = train['full_text'].apply(lambda x: clean_text(x))\n","print(len(train))\n","test['full_text'] = test['full_text'].apply(lambda x: clean_text(x))\n","print(len(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Al149eOmvHuX","executionInfo":{"status":"ok","timestamp":1692759616794,"user_tz":240,"elapsed":10645,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"32823d4c-af52-4bcc-90c2-9264b90d9aff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3911\n","3\n"]}]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"LNopDnVMQ14T"}},{"cell_type":"markdown","source":["The bare RoBERTa Model transformer outputting raw hidden-states without any specific head on top."],"metadata":{"id":"_cfo3JAGTn3F"}},{"cell_type":"code","source":["class FeedBackModel(nn.Module):\n","    def __init__(self):\n","        super(FeedBackModel, self).__init__()\n","        self.backbone = transformers.AutoModel.from_pretrained(Config['MODEL_NAME'])\n","        self.drop = nn.Dropout(0.3)\n","\n","        if 'large' in Config['MODEL_NAME']:\n","            self.fc = nn.Linear(1024, Config['N_LABELS'])\n","        else:\n","            self.fc = nn.Linear(768, Config['N_LABELS'])\n","\n","    def foward(self, input_ids, attention_mask):\n","        '''\n","        output_dicts return dict contains 2 keys:\n","        (1). last_hidden_states: raw hidden_states.\n","        (2). pooler_outputs: [CLS] pooled: tensor representing pooled output of [CLS] token. People usually use this token for fine-tuning classification task. We can try average\n","        pooling. In this project we will use average pooling instead\n","        '''\n","\n","        # Get RoBERTA outputs\n","        outputs_dict = self.backbone(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n","\n","        # Use average pooling over all tokens\n","        # calculated by taking the weighted average of the token embeddings using the attention mask to account for padding tokens.\n","        # This allows you to compute a meaningful average over the actual tokens in each sequence.\n","        avg_pooled_output = torch.sum(outputs_dict['last_hidden_state'] * attention_mask.unsqueeze(-1), dim=1) / attention_mask.sum(dim=1, keepdim=True)\n","\n","        output = self.drop(avg_pooled_output)\n","        output = self.fc(output)\n","        return output\n"],"metadata":{"id":"0tJNcgtTQ206"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Optimizer"],"metadata":{"id":"U7gSLeIRcpQD"}},{"cell_type":"code","source":["def yield_optimizer(model):\n","    \"\"\"\n","    Returns optimizer for specific parameters\n","    \"\"\"\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {\n","            \"params\": [\n","                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": 0.003,\n","        },\n","        {\n","            \"params\": [\n","                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","    return transformers.AdamW(optimizer_parameters, lr=Config['LR'])"],"metadata":{"id":"AqMZAP5zcq56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trainer Class"],"metadata":{"id":"mEnw82RtdMm3"}},{"cell_type":"code","source":["class Trainer:\n","    def __init__(self, dataloaders, optimizer, model, loss_fns, scheduler, device='cuda:0'):\n","        # dataloaders\n","        self.train_loader, self.valid_loader = dataloaders\n","        # define loss functions\n","        self.train_loss_fn, self.valid_loss_fn = loss_fns\n","\n","        self.scheduler = scheduler\n","        self.optimizer = optimizer\n","        self.model = model\n","\n","        self.device = torch.device(device)\n","\n","    # Training procedure\n","    def train_one_epoch(self):\n","        def _convert_if_not_tensor(self, x, dtype):\n","            if dtype == \"infer\":\n","                dtype = x.dtype\n","            if self._tensor_check(x):\n","                return x.to(self.device, dtype=dtype)\n","            else:\n","                return torch.tensor(x, dtype=dtype, device=self.device)\n","\n","        def _tensor_check(self, x):\n","            return isinstance(x, torch.Tensor)\n","\n","        '''\n","        Trains the model for 1 epoch\n","        '''\n","        self.model.train()\n","\n","        # training loop for 1 epoch\n","        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n","        train_preds, train_targets = [], []\n","        total_loss = 0.0\n","\n","        for bnum, (inputs, targets) in train_pbar:\n","            for k, v in inputs.items():\n","                inputs[k] = self._convert_if_not_tensor(v, dtype=\"infer\")\n","\n","            targets = self._convert_if_not_tensor(targets, dtype=torch.float)\n","\n","            with autocast(enabled=True):\n","                # forward pass\n","                outputs = self.model(inputs)\n","\n","                # calculate loss\n","                loss = self.train_loss_fn(outputs, targets)\n","                # accumulate batch loss\n","                total_loss += loss.item()\n","\n","                # backpropogation\n","                Config['scaler'].scale(loss).backward()\n","                Config['scaler'].step(self.optimizer)\n","                Config['scaler'].update()\n","                self.optimizer.zero_grad()\n","                # scheduler adjusts the learning rate or other hyperparameters of an optimization\n","                self.scheduler.step()\n","\n","                # Console log\n","                train_pbar.set_description('loss: {:.2f}'.format(loss.item()))\n","\n","            train_targets.expend(targets.cpu().detach().numpy().tolist())\n","            train_preds.expend(outputs.cpu().detach().numpy().tolist())\n","\n","        # tidy\n","        del outputs, targets, inputs, loss_itm, loss\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        return {'train_preds': train_preds, 'train_targets': train_targets, 'loss_history': total_loss/len(self.train_loader)}\n","\n","    #-------------------------------------------\n","    def valid_one_epoch(self):\n","        '''\n","        Validate the model for 1 epoch\n","        '''\n","        self.model.eval()\n","\n","        valid_pbar = tqdm(enumerate(self.valid_loader), total=len(self.valid_loader))\n","        valid_preds, valid_targets = [], []\n","        total_valid_loss = 0.0\n","\n","        for idx, (inputs, targets) in valid_pbar:\n","            for k, v in inputs.items():\n","                inputs[k] = self._convert_if_not_tensor(v, dtype='infer')\n","\n","            targets = self._convert_if_not_tensor(targets, dtype=torch.float)\n","\n","            outputs = self.model(inputs)\n","            valid_loss = self.valid_loss_fn(outputs, targets)\n","            # accumulate batch loss\n","            total_valid_loss += valid_loss.item()\n","\n","            valid_pbar.set_description('val_loss: {:.2f}'.format(valid_loss.item()))\n","\n","            valid_targets.extend(targets.cpu().detach().numpy().tolist())\n","            valid_preds.extend(outputs.cpu().detach().numpy().tolist())\n","\n","        # tidy\n","        del outputs, inputs, targets, valid_loss\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        return {'valid_preds': valid_preds, 'valid_targets': valid_targets, 'loss_history': total_valid_loss/len(self.valid_loader)}\n","\n","    #---------------------------------------------\n","\n","    def fit(self, epochs=10):\n","        '''\n","        Complete training and validation process\n","        '''\n","        best_loss = int(1e+7)\n","        best_model = None\n","        # total_loss for train/ valid across n epochs\n","        train_history, valid_history = [], []\n","\n","        # Training for each epoch\n","        for epx in range(epochs):\n","            print('Epoch: {}/{}'.format(epx+1, epochs))\n","\n","            train_outputs = self.train_one_epoch()\n","            train_preds, train_targets, train_loss = train_outputs.values()\n","            train_history.append(train_loss)\n","\n","            train_mcrmse = MCRMSE(train_targets, train_preds)\n","            print('Training MCRMSE: {:.4f}'.format(train_mcrmse))\n","\n","\n","            valid_outputs = self.valid_one_epoch()\n","            valid_preds, valid_targets, valid_loss = valid_outputs.values()\n","            valid_history.append(valid_loss)\n","\n","            valid_mcrmse = MCRMSE(valid_targets, valid_preds)\n","            print('Validation MCRMSE: {:.4f}'.format(valid_mcrmse))\n","\n","            if valid_mcrmse < best_loss:\n","                best_loss = valid_mcrmse\n","                best_model = model\n","                path = '/Models/val_loss{}'.format(best_loss)\n","                torch.save(self.best_model.state_dict(), path)\n","                print('Model saved! Validation Loss: {:.4f}'.format(best_loss))\n","\n","        np.save('train_history', train_history)\n","        np.save('valid_history', valid_history)\n","\n","        return {'best_valid_mcrmse': best_loss, # best across all epochs\n","                'best_model': best_model,\n","                'train_history': train_history,\n","                'valid_history': valid_history}\n"],"metadata":{"id":"KZiTBcNJcu-o","executionInfo":{"status":"ok","timestamp":1692762571417,"user_tz":240,"elapsed":161,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"TjJk2WV8JlWt"}},{"cell_type":"code","source":["# Setup environment for training. Use GPU.\n","if torch.cuda.is_available():\n","    print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","    DEVICE = torch.device('cuda:0')\n","else:\n","    print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n","    DEVICE = torch.device('cpu')\n","\n","data = train\n","# Shuffle and reset index for the training data\n","data = data.sample(frac=1).reset_index(drop=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GbHhWWKhJmcX","executionInfo":{"status":"ok","timestamp":1692759629625,"user_tz":240,"elapsed":174,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"7da47856-26d4-499b-ca1b-0374ba3b0cd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[INFO] GPU not found. Using CPU: x86_64\n","\n"]}]},{"cell_type":"code","source":["text = data[['full_text']]\n","labels = data[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']]\n","per_fold_predictions = {}"],"metadata":{"id":"2J3G3LXoJ3lI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use Multilabel Stratified KFolds training and cross validation because we are dealing with multi-targets regression\n","kf = MultilabelStratifiedKFold(n_splits=Config['SPLITS'], shuffle=True)"],"metadata":{"id":"fxus89CSKjwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = FeedBackModel().to(DEVICE)\n","\n","for fold, (train_idx, valid_idx) in enumerate(kf.split(X=text, y=labels.values)):\n","    '''\n","    fold (int): current index of the fold\n","    train_idx (np.array): 1D numpy array of indices from the data dedicated for train dataset in this fold\n","    valid_idx (np.array): 1D numpy array of indices from the data dedicated for valid dataset in this fold\n","    '''\n","    print('Fold: {}'.format(fold))\n","\n","    # Partition\n","    train_data = data.loc(train_idx)\n","    valid_data = data.loc(valid_idx)\n","\n","    # DataLoader customizable class\n","    train_set = FeedBackDataset(train_data)\n","    valid_set = FeedBackDataset(valid_data)\n","\n","    # Load to DataLoader\n","    train_loader = DataLoader(\n","        train_set,\n","        batch_size = Config['TRAIN_BS'],\n","        shuffle = True,\n","        num_workers = 8\n","    )\n","    valid_loader = DataLoader(\n","        valid_set,\n","        batch_size = Config['VALID_BS'],\n","        shuffle = True,\n","        num_workers = 8\n","    )\n","\n","    # Training Loop\n","    optimizer = yield_optimizer(model)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","        optimizer,\n","        T_0 = Config['T_0'],\n","        eta_min = Config['η_min']\n","    )\n","    # Define loss function\n","    train_loss_fn, valid_loss_fn = nn.SmoothL1Loss(), nn.SmoothL1Loss()\n","\n","    # Trainer module\n","    trainer = Trainer(\n","        dataloaders = (train_loader, valid_loader),\n","        loss_fns = (train_loss_fn, valid_loss_fn),\n","        optimizer = optimizer,\n","        model = model,\n","        scheduler = scheduler\n","    )\n","\n","    best_predictor = trainer.fit(\n","        epochs = Config['NB_EPOCHS']\n","    )\n","    # Move the model back to cpu\n","    model.cpu()\n","\n","    per_fold_predictions['fold_{}'.format(fold)] = best_predictor\n","\n","    del best_predictor, trainer, train_loss_fn, valid_loss_fn, model, optimizer, scheduler\n","    del train_data, valid_data, train_set, valid_set, train_loader, valid_loader, train_idx, valid_idx\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n"],"metadata":{"id":"sM_8GDgnW6-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"mo1Q6pNsaUcn"}},{"cell_type":"code","source":["best_mcrmse = int(1e+7)\n","best_model = None\n","\n","# Compare best_valid_mcrmse from best_model across K-Folds\n","for _, predictor in per_fold_predictions.items():\n","    if best_mcrmse < predictor['best_valid_mcrmse']:\n","        best_mcrmse = predictor['best_valid_mcrmse']\n","        best_model = predictor['best_model']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4Jg8kIgaTvR","executionInfo":{"status":"ok","timestamp":1692763789241,"user_tz":240,"elapsed":331,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"763e9f10-bdb2-444a-f5fd-4dc9024c00df"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["fold: 0, train_idx: (3129,), valid_idx: (782,)\n","fold: 1, train_idx: (3129,), valid_idx: (782,)\n","fold: 2, train_idx: (3128,), valid_idx: (783,)\n","fold: 3, train_idx: (3129,), valid_idx: (782,)\n","fold: 4, train_idx: (3129,), valid_idx: (782,)\n"]}]}]}